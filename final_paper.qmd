---
title: "Project Paper"
format: html
editor: visual
---

# **Prediction of Wind Event Devastation**

## Team Windows Group Members

Cassie Chou, JHED ID: cchou24, email: cchou24\@jh.edu\
Kate Brown, JHED ID: kbrow275, email: kbrow275\@jh.edu\
Grace Brooks, JHED ID: mbrook66, email: mbrook66\@jh.edu\
Dhruthi Mandavilli, JHED ID: dmandav2, email: dmandav2\@jh.edu

## Question

Can we model wind event devastation (aggregate statistic including direct and indirect in- jury/deaths, damage to property, damage to crops) based on factors like location, magnitude, wind speed, etc.?

## Goals and Importance

The primary goals of our project were the following:

1.  Understand the relationship between wind event devastation and several characteristics of the event such as time, location, and wind magnitude.

2.  Create an aggregate statistic that represents wind event devastation.

3.  Develop a machine learning model that would use relevant predictors, such as wind magnitude, storm time duration, and location, to predict this statistic.

4.  Make our results available and digestible to the public on a website.

Our aggregate statistic represents a combination of indirect and direct injuries and death, damage to property, and damage to crops caused by the wind event.

Similar to how hurricane categorization can help governments and citizens plan and prepare for upcoming storms, we hope that predicting wind event devastation will help protect vulnerable communities. If we can predict wind event devastation, we can allocate more resources to vulnerable locations and warn vulnerable populations. By giving governmental bodies a better idea of how much devastation to prepare for, we hope to motivate wind event preparation and ultimately reduce this devastation and speed up recovery.

## Background

With the climate change crisis, there has been an increase in extreme weather events over the past decade, and that trend is only expected to continue. We decided that we wanted to look into these extreme events and see what type of analysis we could perform on one or multiple of them. Our initial research found a few articles that used past data on multiple tornado characteristics and machine modeling techniques to predict magnitude\[Jacquot\] and damage\[Diaz and Maxwell\] of tornadoes. We also found an article that did similar modeling on thunderstorms to better equip forecasters and the general public to prepare for storms that could turn into tornadoes\[FAR AFIELD\]. We decided that we wanted to approach our project in a similar way, but investigate a different extreme weather event: wind events.

## Import Packages

```{r}
library(httr)
library(purrr)
library(R.utils)
library(readr)
library(ggplot2)
library(tidyr)
library(dplyr)
library(stringr)
```

## Downloading the Data

We found a dataset with data that fit our goals in the NOAA Storm Event database. This data was available as .csv files for each year that we could download by simply clicking. Initially, we were not sure the best approach to download them in a non-trivial way. We considered some sort of data mining approach, or using something like wget from the command line. However, we did not think that the format would not work properly. We ended up using the map function from the purrr R package. Since the site had multiple .csv files we were interested in, the map function allowed us to run through them and only download the specific files we were interested in. So, we created a function to download a .csv file and paired it with map() to obtain the files for the years we were interested in (2008, 2013, 2018). This method downloaded the proper files to our computer, however they were zipped and not usable. So, we had to go back into our function and rework the code so that it would unzip and read in the downloaded files. After this fix, everything worked as we had intended.

```{r}
#create location to save the data files
storm_data <- "storm_events_csvs"
if(!dir.exists(storm_data)){
  dir.create(storm_data)
}

#write a function to download and unzip csv file
download_and_unzip <- function(url) {
  tryCatch({
    #extract proper file name
    filename <- basename(url)
    destfile <- file.path(storm_data, filename)
    
    #download the file
    response <- GET(url, write_disk(destfile, overwrite = TRUE))
    if (status_code(response) == 200) {
      message("Downloaded: ", filename)
      
      #check if the file is a .gz and unzip
      if (grepl("\\.gz$", filename)) {
        decompressed_file <- sub("\\.gz$", "", destfile)
        gunzip(destfile, destname = decompressed_file, overwrite = TRUE)
        message("Decompressed: ", decompressed_file)
      }
    } else {
      message("Failed to download: ", url)
    }
  }, error = function(e) {
    message("Error downloading ", url, ": ", e$message)
  })
}

#define the base url site and specific files we want to download
base_url <- "https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/"
files_to_download <- c(
  "StormEvents_details-ftp_v1.0_d2008_c20240620.csv.gz",
  "StormEvents_details-ftp_v1.0_d2013_c20230118.csv.gz",
  "StormEvents_details-ftp_v1.0_d2018_c20240716.csv.gz"
)
urls <- paste0(base_url, files_to_download)

#use map from purrr to download the files
map(urls, download_and_unzip)

#read csv files and make data frames
read_csvs <- function(directory) {
  tryCatch({
    #list the csv files available
    csv_files <- list.files(directory, pattern = "\\.csv$", full.names = TRUE)
    
    #read in files and make into data frame
    walk(csv_files, function(file) {
      #create variable name to make dataframe
      data_frame_name <- make.names(gsub("\\.csv$", "", basename(file)))
      assign(data_frame_name, read_csv(file, col_types = cols()), envir = .GlobalEnv)
      message("Data frame created: ", data_frame_name)
    })
  }, error = function(e) {
    message("Error reading CSV files: ", e$message)
  })
}

read_csvs(storm_data)

```

```{r}
eight = StormEvents_details.ftp_v1.0_d2008_c20240620
thirteen = StormEvents_details.ftp_v1.0_d2013_c20230118
eighteen = StormEvents_details.ftp_v1.0_d2018_c20240716
```

## Data Cleaning

In order to analyze the data from our years of interest, 2008,2013,2018, we filtered the csv files to only include events that involved wind since that was what was of interest to us. Since we were only looking at between wind event devastation and  time, location, and wind magnitude we removed all the columns that included data that did not contribute to these categories. There was a lot of missing data so in order to deal with that we removed all rows that had an NA in the columns of event type, state, month, magnitude and latitude because these columns were important when making the model. In addition if there were NA values in any of the devastation columns we replaced it with the value of 0 and made the assumption that if the value was not filled out no damage or injuries occurred.

```{r}
clean_data = function(data) {
cleaned_data = data %>% 
  filter(grepl("wind", EVENT_TYPE, ignore.case = TRUE)) %>% #filter to only wind events
  distinct() %>% #remove duplicate rows 
  select(-EVENT_NARRATIVE, -EPISODE_NARRATIVE, -END_RANGE, -END_AZIMUTH, -END_LOCATION, -BEGIN_RANGE, -BEGIN_AZIMUTH, -BEGIN_LOCATION, -TOR_F_SCALE, - TOR_LENGTH, -TOR_WIDTH, -TOR_OTHER_WFO, -TOR_OTHER_CZ_STATE, -TOR_OTHER_CZ_FIPS, -TOR_OTHER_CZ_NAME, -FLOOD_CAUSE, -SOURCE, -CZ_TIMEZONE, -CZ_TYPE, -WFO, -CZ_FIPS, -CZ_NAME, -STATE_FIPS, -EPISODE_ID, -END_DAY, - END_TIME, -END_YEARMONTH, -BEGIN_TIME, -BEGIN_DAY, -BEGIN_YEARMONTH, -DATA_SOURCE, -CATEGORY) %>%
  filter(complete.cases(EVENT_TYPE, STATE, MONTH_NAME, MAGNITUDE, BEGIN_LAT)) %>%  #remove any rows that have an na in these columns
    mutate(DAMAGE_CROPS = str_remove(DAMAGE_CROPS, "K"))  #remove K 

cleaned_data$DAMAGE_CROPS = as.numeric(cleaned_data$DAMAGE_CROPS)

#change M values in damage property to K
cleaned_data$DAMAGE_PROPERTY = str_replace(cleaned_data$DAMAGE_PROPERTY,  "(\\d+(\\.\\d+)?)M",  function(x) {
  number = as.numeric(str_extract(x, "\\d+(\\.\\d+)?"))
 paste0(number * 10000, ".00K") })

cleaned_data = cleaned_data %>%
  mutate(DAMAGE_PROPERTY = str_remove(DAMAGE_PROPERTY, "K"))

cleaned_data$DAMAGE_PROPERTY = as.numeric(cleaned_data$DAMAGE_PROPERTY)

#make all NA values 0 
#assume values no filled out in this column range means no damage/deaths/injuries 
cleaned_data= cleaned_data %>%
  mutate_at(vars(INJURIES_DIRECT:DAMAGE_CROPS), 
            ~ifelse (is.na(.) | . == "", 0, .))
}
cleaned_eight = clean_data(eight)
cleaned_thirteen = clean_data(thirteen)
cleaned_eighteen = clean_data(eighteen)
```

## Combine Data and Create Aggregate Statistic

There are six variables included in the calculation of the aggregate statistic: direct deaths, indirect deaths, direct injury, indirect injury, damage to property, and damage to crops. Within each variable, we scaled each value to be from zero to one using the following formula: (value - min(Variable))/(max(Variable) - min(Variable)). Once each variable is scaled to be from zero to one, we summed them to get an aggregate statistic. Because many of the wind events had little damage, this value was often very small and hard to interpret. Since we’re interested in the devastation of wind events relative to other wind events, we decided to scale and bin the aggregate such that:

-   0 - No Devastation

-   1 - Minimal Devastation

-   2 - Low Devastation

-   3 - Moderate Devastation

-   4 - Most Devastation

To scale the aggregate, we first set all rows with 0 for the aggregate value to be 0. Then, we removed all of these rows and found the quantiles of the aggregate statistic for the remaining rows. Any values in the first quartile were labeled as 1, any in the second as 2, any in the third as 3, and the remaining values in the fourth as 4. This made the aggregate more interpretable.

```{r combineddata}
# Combine Data
combined_data <- rbind(cleaned_eight, cleaned_thirteen, cleaned_eighteen)

# Reformat Date, Add storm time duration and change in lat/lon values
combined_data <- combined_data %>% mutate(BEGIN_DATE_TIME = as.POSIXct(BEGIN_DATE_TIME, format = "%d-%b-%y %H:%M:%S"), END_DATE_TIME = as.POSIXct(END_DATE_TIME, format = "%d-%b-%y %H:%M:%S"), storm_time_duration = END_DATE_TIME - BEGIN_DATE_TIME, change_lon = END_LON - BEGIN_LON, change_lat = END_LAT - BEGIN_LAT)

# Remove redundant columns
combined_data <- combined_data %>% select(-BEGIN_LAT, -BEGIN_LON, -END_LAT, -END_LON, -BEGIN_DATE_TIME, -END_DATE_TIME)

# Aggregate Stat
combined_data <- combined_data %>% mutate(aggregate_stat = (INJURIES_DIRECT - min(INJURIES_DIRECT))/diff(range(INJURIES_DIRECT)) + (INJURIES_INDIRECT - min(INJURIES_INDIRECT))/diff(range(INJURIES_INDIRECT)) + (DEATHS_DIRECT - min(DEATHS_DIRECT))/diff(range(DEATHS_DIRECT)) + (DEATHS_INDIRECT - min(DEATHS_INDIRECT))/diff(range(DEATHS_INDIRECT)) + (DAMAGE_PROPERTY - min(DAMAGE_PROPERTY))/diff(range(DAMAGE_PROPERTY)) + (DAMAGE_CROPS - min(DAMAGE_CROPS))/diff(range(DAMAGE_CROPS)))

# Scale Aggregate Stat
scale_aggregate <- function(aggregate_stat){
  scaled_stats <- numeric(length(aggregate_stat))
  quantiles_aggregate <- quantile(aggregate_stat[aggregate_stat != 0])
  
  for (i in 1:length(aggregate_stat)){
    if(aggregate_stat[i] == 0){
      scaled_stats[i] <- 0
    } else if (aggregate_stat[i] > 0 && aggregate_stat[i] <= quantiles_aggregate[2]) {
      scaled_stats[i] <- 1
    } else if (aggregate_stat[i] > quantiles_aggregate[2] && aggregate_stat[i] <= quantiles_aggregate[3]) {
      scaled_stats[i] <- 2
    } else if (aggregate_stat[i] > quantiles_aggregate[3] && aggregate_stat[i] <= quantiles_aggregate[4]) {
      scaled_stats[i] <- 3
    } else if (aggregate_stat[i] > quantiles_aggregate[4]) {
      scaled_stats[i] <- 4
    }
  }
  scaled_stats
}

combined_data <- combined_data %>% mutate(scaled_aggregate = scale_aggregate(aggregate_stat))

write.csv(combined_data,"ML_wind_data.csv", row.names = FALSE)

```

## Data Visualizations

**Wind Devastation Categorization**
<<<<<<< HEAD
Our first set of plots were created to visualize the wind devastation categorization created to quantify extreme wind events based on deaths, injuries, and damages as mentioned above. The distribution of wind devastation is then broken down by year, month, and event type as some of our predictor variables.
=======
We used the ggplot2 package to create our histograms and bar plots. Our first set of plots were created to visualize the wind devastation categorization created to quantify extreme wind events based on deaths, injuries, and damages as mentioned above. The distribution of wind devastation is then broken down by year, month, and event type as some of our predictor variables.
>>>>>>> 70cee1d (Add final paper rendered)

```{r}
data <- read.csv("ML_wind_data.csv")

library(ggplot2)
```

```{r}
ggplot(data, aes(x = scaled_aggregate)) +
  geom_histogram(fill = "darkmagenta", color = "black") + 
<<<<<<< HEAD
  labs(x = "Wind Devastation Categorization", y = "Count", fill = "Year", title = "Histogram of the Wind Devastation\nCategorization", caption = "Data from NOAA storm events database from 2008, 2013, and 2018", subtitle = "The majority of events had no devastation followed by\nminimal devastation.") +
=======
  labs(x = "Wind Devastation Categorization", y = "Count", title = "Histogram of the Wind Devastation\nCategorization", caption = "Data from NOAA storm events database from 2008, 2013, and 2018", subtitle = "The majority of events had no devastation followed by\nminimal devastation.") +
>>>>>>> 70cee1d (Add final paper rendered)
  theme_minimal() +
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 19), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

```{r}
ggplot(data, aes(x = scaled_aggregate, fill = factor(YEAR))) +
  geom_histogram(binwidth = (max(data$scaled_aggregate, na.rm = TRUE) - min(data$scaled_aggregate, na.rm = TRUE)) / 15, 
                 alpha = 0.6, position = "dodge", boundary = 0, color = "black") +  
  scale_fill_manual(values = c("2018" = "blue", "2008" = "red", "2013" = "green")) +    labs(x = "Wind Devastation Categorization", y = "Count", fill = "Year", title = "Histogram of the Devastation Categorization\ngrouped by year", caption = "Data from NOAA storm events database from 2008, 2013, and 2018", subtitle  = "Distribution by years are pretty similar but 2008 has the\nmost devastation.") +
  theme_minimal() +
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 19), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 14), 
    axis.text.y = element_text(size = 17), 
    legend.text = element_text(size = 15),
    legend.title = element_text(size = 18)) 
```

```{r}
<<<<<<< HEAD
ggplot(data, aes(x = scaled_aggregate, fill = factor(MONTH_NAME))) +
  geom_histogram(binwidth = (max(data$scaled_aggregate, na.rm = TRUE) - min(data$scaled_aggregate, na.rm = TRUE)) / 15, 
                 alpha = 0.6, position = "dodge", boundary = 0)   + labs(x = "Wind Devastation Categorization", y = "Count", fill = "Year", title = "Histogram of the Devastation Categorization\ngrouped by month", caption = "Data from NOAA storm events database from 2008, 2013, and 2018", subtitle = "Events during summer months appear to cause the most\ndevastation.") +
=======
#order the months
data$MONTH_NAME <- factor(data$MONTH_NAME, 
                          levels = c("January", "February", "March", "April", "May", "June",
                                     "July", "August", "September", "October", "November", "December"))

ggplot(data, aes(x = scaled_aggregate, fill = factor(MONTH_NAME))) +
  geom_histogram(binwidth = (max(data$scaled_aggregate, na.rm = TRUE) - min(data$scaled_aggregate, na.rm = TRUE)) / 15, 
                 alpha = 0.6, position = "dodge", boundary = 0)   + labs(x = "Wind Devastation Categorization", y = "Count", fill = "Month", title = "Histogram of the Devastation Categorization\ngrouped by month", caption = "Data from NOAA storm events database from 2008, 2013, and 2018", subtitle = "Events during summer months appear to cause the most\ndevastation.") +
>>>>>>> 70cee1d (Add final paper rendered)
  theme_minimal() +
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 15), 
    axis.title.y = element_text(size = 15), 
    axis.text.x = element_text(size = 14), 
    axis.text.y = element_text(size = 15), 
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 15)) 
```

```{r}
ggplot(data, aes(x = scaled_aggregate, fill = EVENT_TYPE)) +
  geom_histogram(binwidth = (max(data$scaled_aggregate, na.rm = TRUE) - min(data$scaled_aggregate, na.rm = TRUE)) / 15, 
<<<<<<< HEAD
                 alpha = 0.6, position = "dodge", boundary = 0, color = "black")   + labs(x = "Wind Devastation Categorization", y = "Count", fill = "Year", title = "Histogram of the Devastation Categorization\ngrouped by event type", caption = "Data from NOAA storm events database from 2008, 2013, and 2018", subtitle = "Majority of the data is from thunderstorm wind events.") +
=======
                 alpha = 0.6, position = "dodge", boundary = 0, color = "black")   + labs(x = "Wind Devastation Categorization", y = "Count", fill = "Event Type", title = "Histogram of the Devastation Categorization\ngrouped by event type", caption = "Data from NOAA storm events database from 2008, 2013, and 2018", subtitle = "Majority of the data is from thunderstorm wind events.") +
>>>>>>> 70cee1d (Add final paper rendered)
  theme_minimal() +
  theme(plot.title = element_text(size = 19, face = "bold"), 
    plot.subtitle = element_text(size = 15), 
    axis.title.x = element_text(size = 17), 
    axis.title.y = element_text(size = 17), 
    axis.text.x = element_text(size = 12), 
    axis.text.y = element_text(size = 15), 
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 13)) 
```

These plots show that no devastation is the most common, then minimal and most devastation. With aggregation, the higher 4 categories have similar trends in year, month, and event type with more wind devastation occurring in the summer and 2008 and the even type being mostly thunderstorm wind. However, the no devastation category has a higher frequency in 2018 with some marine thunderstorm wind events also more in the summer months. These trends can be used in the machine learning model for extreme wind event devastation prediction.

**Predictor Variables**
Our second set of plots were created to visualize the machine learning model predictors to assess trends. The predictor variables used were state, month, wind speed, and year.

```{r}
ggplot(data, aes(x = STATE)) +
  geom_bar(fill = "deepskyblue1", color = "black") +
  labs(title = "Number of Extreme Wind Events by State", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "There is state-to-state variability of extreme wind event\noccurrences.",
    x = "U.S. State",
    y = "Number of Extreme Wind Events") +
  theme_minimal() +
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 19), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 6.5, 
      face = "bold", angle = 55, hjust = 1), 
    axis.text.y = element_text(size = 17))
```

```{r}
data$MONTH_NAME <- factor(data$MONTH_NAME, 
                          levels = c("January", "February", 
                                     "March", "April", "May", 
                                     "June", "July", "August", "September", "October", 
                                     "November", "December"))

ggplot(data, aes(x = MONTH_NAME)) +
  geom_bar(fill = "deepskyblue2", color = "black") +
  labs(title = "Number of Extreme Wind Events by Month", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Summer months have higher occurrences of extreme\nwind events.",
    x = "Month",
    y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 19), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17, angle = 45, hjust = 1), 
    axis.text.y = element_text(size = 17))
```

```{r}
ggplot(data, aes(x = MAGNITUDE)) +
  geom_histogram(binwidth = 10, fill = "deepskyblue3", color = "black") +
  labs(title = "Histogram of Extreme Wind Events by\nWind Speed", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
    subtitle = "A wind speed of 50 knots is the most common in\nextreme wind events.",
    x = "Magnitude - Wind Speed (knots)",
    y = "Frequency") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 19), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

```{r}
data$YEAR <- as.factor(data$YEAR)

ggplot(data, aes(x = YEAR)) +
  geom_bar(fill = "deepskyblue4", color = "black") +
  labs(title = "Number of Extreme Wind Events by Year", caption = "Data from NOAA storm events database",
    subtitle = "2008 has a slightly higher occurrence of extreme wind\nevents.",
    x = "Year",
    y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 19), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

These plots show more extreme wind events in midwestern and some southern states, in summer months and 2008 as seen previously, and with wind speeds around 50 knots ranging from 0 to 120 knots. Overall these variables will be useful predictors for our machine learning model.

**Variables in Wind Devastation Categorization**: Zero Counts and Non-Zero Frequencies

The variables in the wind devastation categorization (damages, injuries, and death) have high counts of zeros. Thus, to better visualize our data, for our third set of plots we visualized the counts of zero and non-zero data, and then plotted distributions of the non-zero values.

```{r}
#make category
data$DAMAGE_CROPS_cat <- ifelse(data$DAMAGE_CROPS == 0, "Zero", "Non-Zero")

ggplot(data, aes(x = DAMAGE_CROPS_cat)) +
  geom_bar(fill = "coral1", color = "black") +
  labs(title = "Counts of Non-Zero vs. Zero Crop Damage", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Most extreme weather events have zero crop damage.",
    y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_blank(), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))

#remove zeros
non_zero_DAMAGE_CROPS <- data[data$DAMAGE_CROPS > 0, ]

ggplot(non_zero_DAMAGE_CROPS, aes(x = DAMAGE_CROPS)) +
  geom_histogram(binwidth = 10, fill = "coral3", color = "black") +
  labs(title = "Histogram of Non-Zero Crop Damage From\nExtreme Wind", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Generally, there are low crop damage costs due to\nextreme weather events.",
    x = "Crop Damage (in thousands of dollars)",
    y = "Frequency") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 20), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

```{r}
#make category
data$DAMAGE_PROPERTY_cat <- ifelse(data$DAMAGE_PROPERTY == 0, "Zero", "Non-Zero")

ggplot(data, aes(x = DAMAGE_PROPERTY_cat)) +
  geom_bar(fill = "darkorchid1", color = "black") +
  labs(title = "Counts of Non-Zero vs. Zero Property\nDamage", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "More extreme weather events have zero property\ndamage than non-zero.",
    y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_blank(), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))

#remove zeros
non_zero_DAMAGE_PROPERTY <- data[data$DAMAGE_PROPERTY > 0, ]

ggplot(non_zero_DAMAGE_PROPERTY, aes(x = DAMAGE_PROPERTY)) +
  geom_histogram(fill = "darkorchid3", color = "black") +
  labs(title = "Histogram of Non-Zero Property Damage\nFrom Extreme Wind", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Generally, there are low property damage costs due to\nextreme weather events.",
    x = "Property Damage (in thousands of dollars)",
    y = "Frequency") +
  scale_x_log10() +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 20), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

```{r}
#make category
data$INJURIES_INDIRECT_cat <- ifelse(data$INJURIES_INDIRECT == 0, "Zero", "Non-Zero")

ggplot(data, aes(x = INJURIES_INDIRECT_cat)) +
  geom_bar(fill = "darkseagreen1", color = "black") +
  labs(title = "Counts of Non-Zero vs. Zero Indirect\nInjuries", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Most extreme weather events have zero indirect injuries.",
    y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_blank(), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))

#remove zeros
non_zero_INJURIES_INDIRECT <- data[data$INJURIES_INDIRECT > 0, ]

ggplot(non_zero_INJURIES_INDIRECT, aes(x = INJURIES_INDIRECT)) +
  geom_histogram(binwidth = 1, fill = "darkseagreen3", color = "black") +
  labs(title = "Histogram of Non-Zero Indirect Injuries From\nExtreme Wind", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Generally, there are low indirect injuries due to extreme\nweather events.",
    x = "Indirect Injuries",
    y = "Frequency") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 20), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

```{r}
#make category
data$INJURIES_DIRECT_cat <- ifelse(data$INJURIES_DIRECT == 0, "Zero", "Non-Zero")

ggplot(data, aes(x = INJURIES_DIRECT_cat)) +
  geom_bar(fill = "brown2", color = "black") +
  labs(title = "Counts of Non-Zero vs. Zero Direct Injuries", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Most extreme weather events have zero direct injuries.",
    y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_blank(), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))

#remove zeros
non_zero_INJURIES_DIRECT <- data[data$INJURIES_DIRECT > 0, ]

ggplot(non_zero_INJURIES_DIRECT, aes(x = INJURIES_DIRECT)) +
  geom_histogram(binwidth = 1, fill = "brown4", color = "black") +
  labs(title = "Histogram of Non-Zero Direct Injuries From\nExtreme Wind", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Generally, there are low direct injuries due to extreme\nweather events.",
    x = "Direct Injuries",
    y = "Frequency") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 20), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

```{r}
#make category
data$DEATHS_INDIRECT_cat <- ifelse(data$DEATHS_INDIRECT == 0, "Zero", "Non-Zero")

ggplot(data, aes(x = DEATHS_INDIRECT_cat)) +
  geom_bar(fill = "cornsilk1", color = "black") +
  labs(title = "Counts of Non-Zero vs. Zero Indirect\nDeaths", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Most extreme weather events have zero indirect deaths.",
    y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_blank(), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))

#remove zeros
non_zero_DEATHS_INDIRECT <- data[data$DEATHS_INDIRECT > 0, ]

ggplot(non_zero_DEATHS_INDIRECT, aes(x = DEATHS_INDIRECT)) +
  geom_histogram(binwidth = 1, fill = "cornsilk3", color = "black") +
  labs(title = "Histogram of Non-Zero Indirect Deaths From\nExtreme Wind", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Generally, there are low indirect deaths due to extreme\nweather events.",
    x = "Indirect Deaths",
    y = "Frequency") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 20), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

```{r}
#make category
data$DEATHS_DIRECT_cat <- ifelse(data$DEATHS_DIRECT == 0, "Zero", "Non-Zero")

ggplot(data, aes(x = DEATHS_DIRECT_cat)) +
  geom_bar(fill = "darkolivegreen3", color = "black") +
  labs(title = "Counts of Non-Zero vs. Zero Direct Deaths", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Most extreme weather events have zero direct deaths.",
    y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_blank(), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))

#remove zeros
non_zero_DEATHS_DIRECT <- data[data$DEATHS_DIRECT > 0, ]

ggplot(non_zero_DEATHS_DIRECT, aes(x = DEATHS_DIRECT)) +
  geom_histogram(binwidth = 1, fill = "darkolivegreen", color = "black") +
  labs(title = "Histogram of Non-Zero Direct Deaths From\nExtreme Wind", caption = "Data from NOAA storm events database from 2008, 2013, and 2018",
  subtitle = "Generally, there are low direct deaths due to extreme\nweather events.",
    x = "Direct Deaths",
    y = "Frequency") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 21, face = "bold"), 
    plot.subtitle = element_text(size = 17), 
    axis.title.x = element_text(size = 20), 
    axis.title.y = element_text(size = 19), 
    axis.text.x = element_text(size = 17), 
    axis.text.y = element_text(size = 17))
```

In all six of these variables used in wind devastation categorization, there are more zero values, so plotting non-zero distributions was insightful. These variables show low levels of damages, injuries, and deaths in a hyperbolic shape with some outliers. Trends in these high, non-zero values are useful for our model.

## Programming Paradigms

We employed the supervised learning paradigm when building our machine learning model. We used a random forest model, as the variable we were trying to predict is categorical with more than two choices. Our predictor variables are the following: state, year, month, event type, magnitude, magnitude type, time duration, change in latitude, and change in longitude.

In building the model, we tuned the following hyperparameters using cross validation: number of trees, minimum samples required to be at a leaf node, and the number of features to consider at each split in a tree. During this hyperparameter tuning step, which is typically time consuming for large datasets such as ours, we used parallel computing. In the tune_grid() function, the evaluations of the different combinations of hyperparameters in the grid were evaluated on different cores. This sped up the process. We used the future package.

## Creating Machine Learning Model

```{r}
library(tidymodels)
library(ranger)
library(parallel)
library(future)
```

Preparing the Data

```{r}
# Read in data
ML_data <- read.csv("ML_wind_data.csv")

# Remove variables in aggregate statistic
ML_data <- ML_data %>% select(-INJURIES_DIRECT, -INJURIES_INDIRECT, -DEATHS_DIRECT, -DEATHS_INDIRECT, -DAMAGE_PROPERTY, -DAMAGE_CROPS, -aggregate_stat)

# Prepare remaining data for analysis -- make sure character strings are factors, etc.
ML_data <- ML_data %>% mutate(STATE = as.factor(STATE), YEAR = as.factor(YEAR), MONTH_NAME = as.factor(MONTH_NAME), EVENT_TYPE = as.factor(EVENT_TYPE), MAGNITUDE_TYPE = as.factor(MAGNITUDE_TYPE), scaled_aggregate = as.factor(scaled_aggregate))

ML_data <- na.omit(ML_data)
head(ML_data)

```

Split the Data and Define the Model

```{r}
# Split data into training/test sets
set.seed(1234)
data_split <- initial_split(ML_data, prop = 3/4)
train_data <- training(data_split)
test_data  <- testing(data_split)

# Define Recipe
ML_recipe <- recipe(scaled_aggregate ~ ., data = train_data) %>% update_role(EVENT_ID, new_role = "ID")

# Define Random Forest Model Specs
model_spec <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "permutation")

# Create Workflow
ML_workflow <- workflow() %>%
  add_recipe(ML_recipe) %>%
  add_model(model_spec)

```

### Hyperparameter Tuning with Parallel Computing

```{r}
# Set up parallel computing
numCores <- detectCores()
plan(multisession, workers = numCores)

# Run hyperparameter tuning
## define cross validation folds
cv_folds <- vfold_cv(train_data, v = 3)

## define hyperparameters to tune
parameter_grid <- grid_regular(
  mtry(range = c(2, 7)),
  trees(range = c(50, 250)),
  min_n(range = c(1, 10))
)

## tune hyperparameters
tuned_results <- ML_workflow %>%
  tune_grid(resamples = cv_folds, grid = parameter_grid) 

tuned_results %>%
  collect_metrics()

# Return to work on one core
plan(sequential)

```

Train, Test, and Evaluate Model

```{r}
# Finalize workflow with best hyperparameters
best_params <- tuned_results %>%
  select_best(metric = "roc_auc")
best_params

ML_workflow_final <- ML_workflow %>% finalize_workflow(best_params)

# Train Data
trained_model <- ML_workflow_final %>%
  fit(data = train_data)

# Test data on testing data
test_predict <- predict(trained_model, new_data = test_data) %>%
  bind_cols(test_data)

# Evaluate model
model_eval <- test_predict %>%
  metrics(truth = scaled_aggregate, estimate = .pred_class)

model_eval

# Feature Importance
importance <- trained_model %>%
  extract_fit_engine() %>%
  ranger::importance()

importance

```

## What We Learned

After completing the data visualization it can concluded that the majority of the events being analyzed had no devastation followed by minimal devastation. It can be seen that the distribution of devastation was pretty similar in all 3 years analyzed with 2008 having a little bit more devastation in the minimal, low, moderate and most devastation categories. When looking at the amount of devastation by month the summer months experienced the most amount of devastation. 

In the end, our model with the best hyperparameters had an accuracy of 0.6898446 and a kappa value – which measures how much better our model is than random chance (on a scale from 0 to 1) – of 0.4593361. The most important features in the model were wind magnitude and the state the event took place in. The least important features were changes in latitude and longitude, but that could be due to the fact that many wind events did not record changes in latitude and longitude. Still, our model was better than would be expected from random chance, indicating that the answer to the question motivating our paper is yes: we can model wind event devastation using storm characteristics.

## Conclusion and Future Directions

These results indicate that our statistic for wind categorization can be predicted from our predictors, and that future work can be done to improve the model. This may include using different machine learning models and testing our model on different wind datasets to improve and test accuracy. One might also try different strategies for handling missing data – we chose to list everything missing in the devastation categorization as zero, but perhaps there are better strategies for this.

## Final Analytic Product: Website

Our final analytic product is a public-facing website. It includes 4 pages: About, Data Visualizations, Wind Devastation, and ML Model. The background page describes our goal, background, and main takeaways. The objective of the data visualizations page is to help readers understand our dataset. It includes visualizations of the distributions of the variables used to create the wind devastation categorization and the predictor variables in the ML model. Further, we hope to visualize the relationship between the wind devastation categorization and a few variables to help motivate the machine learning model.  As our target audience is the general public, we have chosen to describe the data download/data cleaning and calculation of the wind event categorization statistic instead of showing all of the code. This is in the Wind Devastation page. We decided to show the full derivation of the machine learning model with simplified annotations to make it simultaneously digestible for readers not familiar with machine learning and helpful for future researchers wanting to build off of our work.

## Links

Github Repository: <https://github.com/jhu-statprogramming-fall-2024/project4-team-windows>

Website: <https://cassiecchou.quarto.pub/team-windows-website/>

## Sources

-   Data Dictionary: <https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/Storm-Data-Bulk-csv-Format.pdf> 

-   NOAA Database: <https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/> 

-   Jacquot, Yves. “Predicting Tornado Magnitude with Machine Learning.” Predicting Tornado Magnitude with Machine Learning, Medium, 11 Oct. 2017, [medium.com/\@yves.jacquot/predicting-tornado-magnitude-with-machine-learning-c76df84d7872](http://medium.com/@yves.jacquot/predicting-tornado-magnitude-with-machine-learning-c76df84d7872).

-   Diaz, Jeremy, and Maxwell B. Joseph. “Predicting property damage from tornadoes with zero-inflated neural networks.” Weather and Climate Extremes, vol. 25, Sept. 2019, p. 100216, <https://doi.org/10.1016/j.wace.2019.100216>.

-   “FAR AFIELD: Researchers Seek out and Study Tornadoes and Severe Weather.” NSSL News, 31 Jan. 2024, [inside.nssl.noaa.gov/nsslnews/2024/01/far-afield-researchers-seek-out-and-study-tornadoes-and-severe-weather/](http://inside.nssl.noaa.gov/nsslnews/2024/01/far-afield-researchers-seek-out-and-study-tornadoes-and-severe-weather/). 
